\documentclass{./solution}

\author{%
    Bhavishya Desai\\[-1mm]
    160194
    \and
    Nikhil Bansal\\[-1mm]
    160447
    \and
    Nishant Maheshwari\\[-1mm]
    160458
    \and
    Harish Rajagopal\\[-1mm]
    160552
    \and
    Akhil Reddy\\[-1mm]
    160613
    \and
    Sameer Meena\\[-1mm]
    160616
}

\setdetails%
{ECO341A}
{Econometrics}
{Assignment}

\begin{document}
    \maketitle

    \begin{solution}[Wooldridge C6.9]
        \section*{Part (i)}
            \begin{table}[H]
                \caption{Coefficients}
                \begin{tabularx}{\textwidth}{C C C}
                    \toprule
                    Feature & Estimate & p-Value \\
                    \midrule
                    (Intercept) & 34.98355 & 9.58 $\times$ 10$^{-7}$ \\
                    exper       &  2.33702 & 2.14 $\times$ 10$^{-8}$ \\
                    age         & -1.06174 & 0.000371 \\
                    coll        & -1.27589 & 0.004892 \\
                    expersq     & -0.07577 & 0.001377 \\
                    \bottomrule
                \end{tabularx}
            \end{table}
            \vspace{-5mm}
            $$ R^2 = 0.1398 $$

        \section*{Part (ii)}
            The limiting value for experience is 15.
            This makes sense, as after 15 years of experience, there is not much left to learn.
            Also, the player must have established his career, and thus gives more chances to his teammates.

        \section*{Part (iii)}
            This implies that better players must be spending less years in college basketball and more in league NBA.\@
            Thus, their values for `\texttt{coll}' will be less.

        \section*{Part (iv)}
            The p-value for the quadratic of age is 0.2699.
            Thus, the coefficient is not significant, and thus it is not needed.
            This matches with the intuition that, keeping experience and education constant, more age leads to less points, as older players' bodies get weaker.

        \section*{Part (v)}
            \begin{table}[H]
                \caption{Coefficients}
                \begin{tabularx}{\textwidth}{C C C}
                    \toprule
                    Feature & Estimate & p-Value \\
                    \midrule
                    (Intercept) &  6.792880 &  3.22 $\times$ 10$^{-14}$ \\
                    points      &  0.077893 &   < 2 $\times$ 10$^{-16}$ \\
                    exper       &  0.219415 &  1.52 $\times$ 10$^{-5}$ \\
                    expersq     & -0.007166 &    0.0102 \\
                    age         & -0.048981 &    0.1623 \\
                    coll        & -0.040560 &    0.4439 \\
                    \bottomrule
                \end{tabularx}
            \end{table}
            \vspace{-5mm}
            $$ R^2 = 0.4872 $$

        \section*{Part (vi)}
            For joint significance testing, using the F-statistic for the linear hypothesis, the p-value is 0.2912.
            This implies that once productivity and seniority are accounted for, age and education do not have significant effects on wages.

        \section*{Code}
            \inputcode{R}{./c6.9.R}

        \section*{Output}
            \inputcode{text}{./c6.9.out}
    \end{solution}


    \begin{solution}[Wooldridge C7.9]
        \section*{Part (i)}
            The fraction of families eligible for the 401(k) plan is: 0.3921.

        \section*{Part (ii)}
            \begin{table}[H]
                \caption{Coefficients}
                \begin{tabularx}{\textwidth}{C C C}
                    \toprule
                    Feature & Estimate & p-Value \\
                    \midrule
                    (Intercept) & -5.063$\times$ 10$^{-1}$ &  4.48$\times$ 10$^{-10}$ \\
                    inc         &  1.245$\times$ 10$^{-2}$ &   < 2$\times$ 10$^{-16}$ \\
                    age         &  2.651$\times$ 10$^{-2}$ &  1.49$\times$ 10$^{-11}$ \\
                    male        & -3.533$\times$ 10$^{-3}$ &      0.77 \\
                    incsq       & -6.165$\times$ 10$^{-5}$ &   < 2$\times$ 10$^{-16}$ \\
                    agesq       & -3.053$\times$ 10$^{-4}$ &  1.26$\times$ 10$^{-11}$ \\
                    \bottomrule
                \end{tabularx}
            \end{table}
            \vspace{-5mm}
            $$ R^2 = 0.09428 $$

        \section*{Part (iii)}
            The coefficients for income and age are significant, but not for gender.
            This implies that 401(k) eligibility is independent of gender, but dependent on income and age.

        \section*{Part (iv)}
            There are no fitted values that are negative or greater than one.

        \section*{Part (v)}
            It is predicted that 2,460 families are eligible for a 401(k) plan.

        \section*{Part (vi)}
            For the 5,638 families not eligible for a 401(k), 81.71\% are predicted to be ineligible.
            For the 3,637 families eligible for a 401(k), 39.29\% are predicted to be eligible.

        \section*{Part (vii)}
            The accuracy is not completely descriptive about the model's performance.
            From the values in the previous part, it seems the model is biased towards predicting ineligibility, which is not evident from the accuracy itself.

        \section*{Part (viii)}
            If a family has someone with an IRA, the estimated probability is higher by 0.0198.
            The p-value for the coefficient of `\texttt{pira}' is 0.1054.
            Hence, it is not statistically different from zero at the 10\% level of significance.

        \section*{Code}
            \inputcode{R}{./c7.9.R}

        \section*{Output}
            \inputcode{text}{./c7.9.out}
    \end{solution}

    \begin{solution}[Stock-and-Watson E6.1]
        \section*{Part (a)}
            The coefficient of smoker is $-253.23$ i.e. if a mother smokes during
            pregnancy it, the \textit{Birthweight} would decrease by $253.23$ units.


            \begin{table}[H]
                \caption{Coefficients of Regression}
                \begin{tabularx}{\textwidth}{C C C}
                    \toprule
                    Feature & Estimate & p-Value \\
                    \midrule
                    (Intercept) & $3432.06$ &  $<$2$\times$ 10$^{-16}$ \\
                    smoker         &  -253.23 &   $<$ 2$\times$ 10$^{-16}$ \\

                    \bottomrule
                \end{tabularx}
            \end{table}
            \vspace{-5mm}

        \section*{Part (b)}
            \subsection*{  (i)}
            From the regression statistics we see that \textit{smoker} is correlated with \textit{alcohol} and \textit{nprevist} and \textit{alcohol} + \textit{nprevist} are determinants for \textit{Birthweight} so omitting
            them leads to  omitted variable bias in the regression estimated in (a).

            \subsection*{ (ii)}
            Yes there is a substantial change in the coefficient for \textit{smoking}.
            It increases from $-253.23$ to $-217.58$ in presence of \textit{nprevist} and \textit{alcohol}. Therefore, regression in Part(a)
            suffers from omitted variable bias.

            \subsection*{(iii)}
            We know,
            birthweight = 3051.25 - 217.58$\times$smoking - 30.49$\times$alcohol  + 34.07$\times$nprevist

            For Jane,

            birthweight = 3051.25 - 217.58 $\times$ 1 - 30.49$\times$0  + 34.07$\times$ 8 = $3106.228 $ grams

            \subsection*{(iv)}
            $R^{2} = 0.0728503$ and $\bar{R}^{2}=0.07192191$.
            $R^{2}$ and $\bar{R}^{2}$  indicate the sample variance explained
            by the regressors.They are very similar because the added variables
            are significant and correlated.

        \section*{Part (c)}
            By using the Frisch-Waugh theorem the coefficient of smoking comes out to be same as Part(b) i.e. 217.58.

        \section*{Part (d)}
            \subsection*{(i)}
            \textit{Tripre1} is excluded from the regression to avoid perfect
            multicollinearity since \textit{Tripre1} = 1 only when  \textit{Tripre0},  \textit{Tripre2} and  \textit{Tripre3} are zero.

            If we include \textit{Tripre1} then it would be linearly expressible
            using \textit{Tripre0},  \textit{Tripre2} and  \textit{Tripre3} i.e.

            \[ t1 = 1 - t0 -t2 -t3 \] and would lead to perfect multicollinearity.

            \subsection*{(ii)}
            Coefficient of tripre0 is -697.9687 which implies that child of a mother
            with zero prenatal visits will have birthweight of 697.9687 less than if she had any prenatal visits.

            \subsection*{ (iii)}
            Coefficient of tripre2 is -100.8373 which implies that child of a mother
            with first pre natal care in 2nd trimester will have birthweight of 100.8373 less.

            Coefficient of tripre3 is -136.9553  which implies that child of a mother
            with first pre natal care in 3rd trimester will have birthweight of 136.9553 less.

            \subsection*{ (iv)}
            The adjusted $\bar{R}^{2}$ is  0.04487327 which is less than Part(b) [0.07192191]. Therefore, the regression in (d) \textbf{DOES NOT} explain a larger fraction of the variance.
            in birth weight than the regression in (b)

        \section*{Code}
            \inputcode{R}{./e6.1.R}

        \section*{Output}
            \inputcode{text}{./e6.1.out}
    \end{solution}
\end{document}
